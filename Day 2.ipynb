{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Towards a universal platform for data science on public and private clouds\n",
    "**KARIM CHINE** *ElasticR*\n",
    "\n",
    "Rosetta hub: spin up sharable data science clouds and dashboard for use, i think.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Density-Based Clustering in Python\n",
    "**Brian Kent** *Dato*\n",
    "\n",
    "- k-means is terrible\n",
    "    - yes. \n",
    "- density based clustering\n",
    "    - assumption: data is drawn from an unknown probability density function (PDF)\n",
    "    - use data to estimate the pdf\n",
    "    - choose a threshold and get the 'upper level set'\n",
    "    - use connected components to build sets\n",
    "    - intersect data with connected components\n",
    "    - assign data to points\n",
    "- problems:\n",
    "    - recover more complex cluster shapes\n",
    "    - don't need to know k\n",
    "    - can automatically find outliers\n",
    "    - requires a distance function\n",
    "    - not as scalable as k-means\n",
    "    - it's impossible to compute the topologically connected components\n",
    "- **DBSCAN**\n",
    "    - Density-Based Spatial Clustering of Applications with Noise (Ester, et al 1996)\n",
    "    - Test of Time award at KDD 2014\n",
    "- Main idea:\n",
    "    - three types of points: core, boundary, noise\n",
    "    - connect core points into clusters\n",
    "    - assign boundary points to clusters\n",
    "\n",
    "- DBSCAN is available in sklearn.\n",
    "    - parameters:\n",
    "        - eps (epsilon)\n",
    "        - min_samples (density level threshold)\n",
    "\n",
    "- DBSCAN is available in graphlab create\n",
    "    - built on sframe and sgraph structures\n",
    "    - composite distances for varied feature types:\n",
    "        - allow different distance functions for different features\n",
    "        - but this doesn't necessarily play nicely with dbscan\n",
    "        - normalization seems like it would be a problem potentially\n",
    "\n",
    "- Level Set Trees are even better\n",
    "    - how to choose density level (min_neighbors/samples)\n",
    "    - changing levels mean starting from scratch\n",
    "    - level set trees describe entire hierarchy\n",
    "        - retrieve in different ways without recomputing\n",
    "    - how to build\n",
    "        - estimate PDF at each data point\n",
    "        - construct a similarity graph on the data\n",
    "            - vertices are data points\n",
    "            - edges represent near neighbors\n",
    "        - remove vertices in order of estimated density\n",
    "        - compute the connected components at each level\n",
    "            - when splits happen, record them\n",
    "        - keep track of connected components at each level\n",
    "    - LSTs are great with complex data\n",
    "- DeBaCl library in python:\n",
    "    - seems worth checking out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing Wireless-Router Timeseries Data with the Density API, Seaborn, and Pandas\n",
    "**JESSICA FORDE** *Columbia University*\n",
    "\n",
    "Tool to show how full library spaces are\n",
    "\n",
    "- Connected client counts are available from assorted locations\n",
    "\n",
    "*(seems like it could be an interesting sort of tool to build for msg/msgs)*\n",
    "- pandas.from_dict on json\n",
    "- find on tiny.cc\n",
    "- dt index.{day, hour, minute}\n",
    "- density_pydata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter\n",
    "**Brian Granger** *Jupyter*\n",
    "\n",
    "- ipython\n",
    "    - started in 2001\n",
    "    - notebook came out in 2011\n",
    "- jupyter\n",
    "    - new project name as of 2015\n",
    "    - ipython still exists; but notebook and other components moved to jupyter\n",
    "    - lots of other kernels\n",
    "        - python (duh)\n",
    "        - julia (well-supported)\n",
    "        - R (potentially useful)\n",
    "        - bash (wtf!)\n",
    "        - logo (wtf! wtf!)\n",
    "        - brainfuck (aaaaaaggggghhh!)\n",
    "- notebook utilities\n",
    "    - nbconvert\n",
    "        - convert notebooks into other formats\n",
    "    - nbviewer\n",
    "        - sort of like nbconvert, but for the webs\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Understanding Probabilistic Topic Models By Simulation\n",
    "**TIMOTHY HOPPER** \n",
    "\n",
    "- Latent Dirichlet Allocation\n",
    "    -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Great Taste, Less Wordy: Document Summarization of Beer Reviews\n",
    "**Ben Fields**\n",
    "\n",
    "LDA for beer reviews\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
