{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Machine Learning with scikit-learn\n",
    "**Andreas Mueller** *NYU Center for Data Science, scikit-learn*\n",
    "\n",
    "http://bit.ly/sklodsc\n",
    "\n",
    "- big list of stuff it can do\n",
    "- current version 0.17\n",
    "- useful stuff:\n",
    "    - train_test_split\n",
    "    - are .fit/.predict/.score the standard methods on models?\n",
    "        - yes! examples used: LinearSVM, RandomForestClassifier\n",
    "    - PCA is pretty easy to run\n",
    "    - preprocessing:\n",
    "        - useful stuff for scaling, etc.\n",
    "        - .transform\n",
    "    - cross validation\n",
    "        - takes a method, data, parameters\n",
    "        - can do stratified cross validation\n",
    "        - ShuffleSplit\n",
    "            - not quite clear on what this is doing differently\n",
    "        - n jobs for parallelization\n",
    "        - scoring\n",
    "    - alternative scoring\n",
    "        - F1 / average_precision / roc_auc\n",
    "        - can multiple scoring be done?\n",
    "    - grid search\n",
    "        - GridSearchCV\n",
    "        - pass a dict with the parameter values\n",
    "        - after instantiation, acts like other classifiers (fit/predict/score)\n",
    "            - .best_params then available\n",
    "    - pipelines\n",
    "        - hook multiple things together\n",
    "        - such as scaler & classifier\n",
    "        - can be used with grid search\n",
    "            - special for the param grid\n",
    "                - 'step\\_\\_param' to set which parameters to modify\n",
    "    - Vectorizers\n",
    "        - for feature creation\n",
    "        - CountVectorizer\n",
    "            - for, eg, bag of words\n",
    "            - includes ngram_range parameter\n",
    "        - TFIDFVectirizer\n",
    "        - HashingVectorizer\n",
    "            - sparse representation, no vocabulary\n",
    "            - useful for streaming\n",
    "            - but collisions, model transparency            \n",
    "    - feature unions\n",
    "        - essentially a way to extract features in different ways\n",
    "    - out of core learning\n",
    "        - partial_fit over batches\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance Pandas\n",
    "###### OR *stuff i really should've already known about pandas*\n",
    "**Jeff Reback** *Continuum*\n",
    "\n",
    "http://tiny.cc/pandaspydata\n",
    "\n",
    "- the beeradvocate data is no longer available\n",
    "    - probably for the reasons ben fields said yesterday\n",
    "- types:\n",
    "    - be careful about data types!\n",
    "- formats:\n",
    "    - formats\n",
    "        - excel is slow\n",
    "        - sql is better\n",
    "        - json is mid\n",
    "        - hdf5 is good\n",
    "        - pickle and msgpack are great\n",
    "    - text data: json is a good idea\n",
    "    - numeric data: json is not so good\n",
    "    - odo library provides a lot of good conversions\n",
    "- data:\n",
    "    - examining data: \n",
    "        - the .str accessor for text data: provides a lot of useful functions that would probably make my life better\n",
    "        - *(tab completion in notebook)*\n",
    "    - datetime64s are better than dates for pandas\n",
    "        - dates are not first class objects in pandas (datetimes are)\n",
    "    - if you are iterating, should be vectorizing\n",
    "    - categoricals & .cat accessor\n",
    "        - should be converting some new fields to categoricals\n",
    "        - maps to integers\n",
    "    - objects are big\n",
    "        - storing objects is not ideal\n",
    "    - *(select_dtypes)*\n",
    "    - *(.info)*\n",
    "- indexing\n",
    "    - use .loc\n",
    "        - you can provide an indexer and the columns you actually want\n",
    "        - it's just more explicit & efficient\n",
    "    - .contains on categorical names\n",
    "        - convert to string: not so good\n",
    "        - method chain: \n",
    "            - use .cat.categories.str.contains to get the categories\n",
    "            - then use those categories with .isin\n",
    "            - use that output as the indexer\n",
    "    - .iloc is purely positional indexer\n",
    "    - multiindexing\n",
    "        - represented by tuples\n",
    "        - pd.IndexSlice is something to know about\n",
    "            - to index by multiple levels\n",
    "            - you can use : to not filter a particular level\n",
    "        - .query takes strings\n",
    "            - sql-like syntax\n",
    "- grouping\n",
    "    - steps: split, apply, combine\n",
    "    - df.groupby takes a grouper\n",
    "        - it can be a series, a mapping, a value...\n",
    "    - .get_group is much more efficient than a selector\n",
    "    - apply, things like .agg\n",
    "        - a user function can be slow!\n",
    "        - can use selectors, or on a single column\n",
    "    - can chain group operations as well\n",
    "    - .agg can be used for mean, stdev, etc.?\n",
    "    - combine:\n",
    "        - stack\n",
    "    - can group by multiple things\n",
    "    - .agg : aggregates one per group\n",
    "    - .transform : output has the same shape\n",
    "        - df.groupby.transform\n",
    "    - .apply : anything goes\n",
    "    - don't groupby a groupby\n",
    "- tidying data\n",
    "    - each variable should form a column\n",
    "    - each observation should form a row\n",
    "    - something else\n",
    "    - .assign method:\n",
    "        - copies data, assigns a new column, returns\n",
    "    - .drop method:\n",
    "        - removes columns\n",
    "    - .melt\n",
    "        - can use to change wide data to long data\n",
    "        - eg, create multiple new rows from one original\n",
    "    - .pivot\n",
    "        - inverse of melt\n",
    "    - .pipe\n",
    "        - new thingg\n",
    "- datetimes\n",
    "    - Grouper(key='blah', freq='D')\n",
    "    - .set_index('timecol')[datetimestring\\:datetimestring]\n",
    "        - the \\: *must* be present\n",
    "    - timezones are better in .17\n",
    "    - .rolling_mean (!) \n",
    "- other libraries\n",
    "- numba & cython\n",
    "    - pandas plays nicely with these two\n",
    "    - cython:\n",
    "        - code can be pretty similar\n",
    "        - needs allocation\n",
    "    - numba:\n",
    "        - numba can do the memory allocation for you \n",
    "        - code just needs @jit\n",
    "        - future support for numba will be even easier\n",
    "- dask\n",
    "    - dask.from_pandas to get dask frame from pandas\n",
    "    - frequently will *just work*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One of these things is not like the others. Automatically detecting outliers.\n",
    "**HOMIN LEE** *Datadog*\n",
    "\n",
    "- problem domain for datadog is, of course, monitoring\n",
    "- outliers vs anomalies\n",
    "- MAD (median absolute deviation)\n",
    "    - $$MAD(D) = median( { |d_i - median(D)|})$$\n",
    "    - tolerance & percent for a full time series being an outlier\n",
    "- DBSCAN\n",
    "    - again, epsilon & min_samples\n",
    "- choice: care about the shapes being similar or alignment?\n",
    "    - DBSCAN is likely to trigger anomaly on bad alignment\n",
    "- hidden parameter: window size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Art and Science of Data Matching\n",
    "**MIKE MULL** \n",
    "\n",
    "https://github.com/mikemull/Notebooks/blob/master/PyDataNYCSlides.ipynb\n",
    "\n",
    "Approximate string comparisons:\n",
    "- Python modules:\n",
    "    - NLTK\n",
    "    - Difflib\n",
    "    - Jellyfish\n",
    "    - more\n",
    "- Algorithms\n",
    "    - Jaro\n",
    "    - JaroWinkler\n",
    "        - quite valuable algorithm\n",
    "    - Jaccard\n",
    "    - SoftTfIdf\n",
    "        - uses TF-IDF with other measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting Started in Computational Sociology with Python\n",
    "**TARA ADISESHAN** *Coral Project*\n",
    "\n",
    "- Collaboration between NYT, Mozilla, Washington Post\n",
    "    - https://coralproject.net\n",
    "    - 'don't read the comments'\\: but community is important\n",
    "    - quite new project\n",
    "- what happens when journalists get involved in comments?\n",
    "    - potential follow ups, better engagement, less toxicity\n",
    "    - hard to fix:\n",
    "        - trolls\n",
    "        - drive-bys (no real discussion)\n",
    "        - low quality contributions\n",
    "        - power-users\n",
    "        - hostile\n",
    "        - scaling problems\n",
    "- so how to help:\n",
    "    - detect toxic behavior\n",
    "    - highlight great discussion\n",
    "    - design inclusive communities\n",
    "    - deal with scale\n",
    "- what kind of questions?\n",
    "\n",
    "- agent-based modeling\n",
    "    - flocking / craig reynolds / boids\n",
    "    - schelling's model: (housing)\n",
    "        - small preferences in who you want to be surrounded by causes big effects\n",
    "    - abm + python:\n",
    "        - mesa\n",
    "        - pyabm\n",
    "        - pycx.sourceforce.net\n",
    "        - ...\n",
    "- 'algorithmic accountability'\n",
    "    - risks: \n",
    "        - grasp of language\n",
    "        - reinforcing biases\n",
    "    - possibilities:\n",
    "        - sentiment analysis\n",
    "        - relevance to article\n",
    "        - topic modeling / hand-crafted? generated?\n",
    "- silly things\n",
    "    - http://haternews.herokuapp.com/\n",
    "- lada adamic\n",
    "    - interesting person to look up \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dask - Parallelizing NumPy/Pandas through Task Scheduling\n",
    "**Jim Crist**\n",
    "\n",
    "http://github.com/jcrist/Dask_PyData_NYC\n",
    "\n",
    "- Big data sets\n",
    "    - how to deal?\n",
    "- Blocked algorithms\n",
    "    - blocked mean as working example\n",
    "        - breaking data into chunks & reducing at the end\n",
    "    - get you parallelism & less memory usage\n",
    "    - if you can figure out how to break it out into blocks\n",
    "- Dask\n",
    "    - parallel computing framework\n",
    "    - leverages python ecosystem\n",
    "    - blocked algorithms & scheduling\n",
    "    - pure python\n",
    "    - collections\n",
    "        - array\n",
    "            - out of core, parallel, n-dimensional array library\n",
    "            - copies numpy interface\n",
    "        - bag\n",
    "            - map, filter, reduce, etc.\n",
    "            - example on http://blaze.pydata.org/blog/2015/09/08/reddit-comments/\n",
    "        - dataframe\n",
    "            - from pandas: dd.from_pandas\n",
    "    - visualizes the computations!\n",
    "    - collections build task graphs\n",
    "        - these are passed on to schedulers\n",
    "        - the graph:\n",
    "            - dictionary of name: task\n",
    "            - tasks are tuples of (func, args...)\n",
    "            - args can be names, values, or tasks\n",
    "        - some things cannot be encoded\n",
    "            - can create graphs directly and pass to schedulers\n",
    "    - dask.imperative\n",
    "        - decorate functions with @do to build up\n",
    "    - distributed scheduler\n",
    "        - in the works\n",
    "        - http://distributed.readthedocs.org/en/latest\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Your Powers For Good\n",
    "**Peter Bull** *DrivenData* @drivendataorg\n",
    "\n",
    "- datascience in the social sector\n",
    "    - not many data science people\n",
    "    - not much money to pay them in nonprofits\n",
    "- how to get involved\n",
    "    - join data for good organizations\n",
    "        - datakind\n",
    "        - code for america\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
